{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc5b9dfd-e5a3-485b-898b-800a22a5c89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import os\n",
    "import yaml\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from variable_mapping import variable_mapping\n",
    "import datetime\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "CURRENT_PATH = os.getcwd()\n",
    "sys.path = [path for path in sys.path if '../dependencies/GHOST_standards/' not in path]            \n",
    "sys.path.insert(1, os.path.join(CURRENT_PATH, '../dependencies/GHOST_standards/1.5'))\n",
    "from GHOST_standards import standard_parameters, get_standard_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9045d825-9ec6-4733-bd45-6d0b210c5674",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cf9a556-fcd2-4926-9533-c1992a4ce0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables = ['sconcno2']\n",
    "#resolution = 'daily'\n",
    "\n",
    "variables = ['sconco3']\n",
    "resolution = 'hourly'\n",
    "target_start_date = datetime.datetime(2018, 1, 1, 0)\n",
    "target_end_date = datetime.datetime(2018, 12, 31, 23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3182f7a5-fb1e-4846-9477-52f9af6073d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coverages_dict = {'P0000-00-00T01:00:00': 'hourly', \n",
    "                  'P0000-00-01T00:00:00': 'daily', \n",
    "                  'P0000-01-00T00:00:00': 'monthly'}\n",
    "\n",
    "units_dict = {'nmol/mol': 'nmol_per_mol',\n",
    "              'ug/m3': 'ug_per_m3',\n",
    "              'ug N/m3': 'ug_per_m3',\n",
    "              'ug S/m3': 'ug_S_per_m3',\n",
    "              'pmol/mol': 'pmol_mol'\n",
    "              } "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600d3f7c-9f41-44b0-a4a6-dbe5d6116d5a",
   "metadata": {},
   "source": [
    "# Get ACTRIS variable mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1139992f-b571-4bc7-90ed-f0332a6fe40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_variable_mapping_file():\n",
    "    result = {\n",
    "        value['preferred_term'].replace('\"', ''): {'var': key[2], 'units': key[0]}\n",
    "        for key, value in variable_mapping.items()\n",
    "    }\n",
    "    \n",
    "    with open('variable_mapping.yaml', 'w') as file:\n",
    "        yaml.dump(result, file, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b750ad32-4d97-4dca-8f2a-ed58d63b4d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_variable_mapping_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebd12cc4-508c-41f8-b6c3-6b3ef5e56eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_mapping = yaml.safe_load(open(os.path.join(CURRENT_PATH, 'variable_mapping.yaml')))\n",
    "variable_mapping = {k: v for k, v in variable_mapping.items() if k.strip() and v}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46f1930-b854-4ea1-b85d-82c8b334eb3c",
   "metadata": {},
   "source": [
    "# Get BSC-ACTRIS parameters dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c86d22c1-7dbb-4410-99ff-4407b3e7c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_actris_variables_file():\n",
    "    with open('actris_variables.csv', mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for key in variable_mapping.keys():\n",
    "            writer.writerow([key, variable_mapping[key]['var']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24f7ca2b-b623-46c6-be98-fe5070c716ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_actris_variables_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c118ac6-82c3-471a-861e-3ce3363e3c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ghost_variables_file():    \n",
    "    with open('ghost_variables.csv', mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "        writer = csv.writer(file)\n",
    "        for key in standard_parameters.keys():\n",
    "            writer.writerow([standard_parameters[key]['long_parameter_name'], standard_parameters[key]['bsc_parameter_name'], ', '.join( standard_parameters[key]['ebas_parameter_name'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5cc7adb-4ba6-4c31-95a5-f901ebfe0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create_ghost_variables_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06a99ac2-4ddd-4670-b1a6-b298fba7d4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sconco3': 'ozone mass concentration',\n",
       " 'sconcno2': 'nitrogen dioxide mass concentration',\n",
       " 'sconcso2': 'sulfur dioxide mass concentration',\n",
       " 'sconcco': 'carbon monoxide amount fraction',\n",
       " 'sconcch4': 'methane amount fraction',\n",
       " 'sconcglyox': 'glyoxal mass concentration',\n",
       " 'sconcc2h4': 'ethene amount fraction',\n",
       " 'sconcald2': 'acetaldehyde mass concentration',\n",
       " 'sconcc2h6': 'ethane amount fraction',\n",
       " 'sconcetoh': 'ethanol mass concentration',\n",
       " 'sconcc3h6': 'propene amount fraction',\n",
       " 'sconcc3h8': 'propane amount fraction',\n",
       " 'sconcc4h6': '1,3-butadiene amount fraction',\n",
       " 'sconcc4h8': '1-butene amount fraction',\n",
       " 'sconcisop': 'isoprene amount fraction',\n",
       " 'sconcc5h12': 'n-pentane amount fraction',\n",
       " 'sconcc6h6': 'benzene amount fraction',\n",
       " 'sconcc6h14': 'n-hexane amount fraction',\n",
       " 'sconcc7h8': 'toluene',\n",
       " 'sconcmpxyl': 'm/p-xylenes amount fraction',\n",
       " 'sconcmxyl': 'm-xylene amount fraction',\n",
       " 'sconcoxyl': 'o-xylene amount fraction',\n",
       " 'sconcc9h12': '1,2,4-trimethylbenzene amount fraction',\n",
       " 'sconcc10h16': 'monoterpenes amount fraction',\n",
       " 'sconcbap': 'gas and particle benzo(a)pyrene mass concentration',\n",
       " 'sconcnh3': 'ammonia mass concentration',\n",
       " 'sconchno3': 'nitric acid mass concentration',\n",
       " 'sconchcho': 'formaldehyde mass concentration',\n",
       " 'sconchcl': 'hydrochloric acid mass concentration',\n",
       " 'sconchggem': 'gaseous elemental mercury mass concentration',\n",
       " 'sconchggom': 'gaseous mercury oxides mass concentration',\n",
       " 'sconchgtgm': 'gaseous elemental mercury and mercury oxides mass concentration',\n",
       " 'sconcal': 'aerosol particle aluminium mass concentration',\n",
       " 'sconcas': 'aerosol particle arsenic mass concentration',\n",
       " 'sconcbappm': 'aerosol particle benzo(a)pyrene mass concentration',\n",
       " 'sconcbc': 'aerosol particle equivalent black carbon mass concentration',\n",
       " 'sconcc': 'aerosol particle total carbon mass concentration',\n",
       " 'sconcca': 'aerosol particle calcium mass concentration',\n",
       " 'sconccd': 'aerosol particle cadmium mass concentration',\n",
       " 'sconccl': 'aerosol particle chloride mass concentration',\n",
       " 'sconccobalt': 'aerosol particle cobalt mass concentration',\n",
       " 'sconccr': 'aerosol particle chromium mass concentration',\n",
       " 'sconccu': 'aerosol particle copper mass concentration',\n",
       " 'sconcdu': 'aerosol particle mineral dust mass concentration',\n",
       " 'sconcec': 'aerosol particle elemental carbon mass concentration',\n",
       " 'sconcfe': 'aerosol particle iron mass concentration',\n",
       " 'sconchg': 'aerosol particle mercury mass concentration',\n",
       " 'sconck': 'aerosol particle potassium mass concentration',\n",
       " 'sconcmg': 'aerosol particle magnesium mass concentration',\n",
       " 'sconcmn': 'aerosol particle manganese mass concentration',\n",
       " 'sconcmsa': 'aerosol particle methanesulfonic acid mass concentration',\n",
       " 'sconcna': 'aerosol particle sodium mass concentration',\n",
       " 'sconcnh4': 'aerosol particle ammonium mass concentration',\n",
       " 'sconcnh4no3': 'aerosol particle ammonium nitrate mass concentration',\n",
       " 'sconcni': 'aerosol particle nickel mass concentration',\n",
       " 'sconcno3': 'aerosol particle nitrate mass concentration',\n",
       " 'sconcoc': 'aerosol particle organic carbon mass concentration',\n",
       " 'sconcpb': 'aerosol particle lead mass concentration',\n",
       " 'sconcse': 'aerosol particle selenium mass concentration',\n",
       " 'sconcso4': 'aerosol particle sulphate mass concentration',\n",
       " 'sconcv': 'aerosol particle vanadium mass concentration',\n",
       " 'sconczn': 'aerosol particle zinc mass concentration',\n",
       " 'absco370': 'aerosol particle light absorption coefficient',\n",
       " 'absco467': 'aerosol particle light absorption coefficient',\n",
       " 'absco470': 'aerosol particle light absorption coefficient',\n",
       " 'absco520': 'aerosol particle light absorption coefficient',\n",
       " 'absco522': 'aerosol particle light absorption coefficient',\n",
       " 'absco525': 'aerosol particle light absorption coefficient',\n",
       " 'absco528': 'aerosol particle light absorption coefficient',\n",
       " 'absco530': 'aerosol particle light absorption coefficient',\n",
       " 'absco550': 'aerosol particle light absorption coefficient',\n",
       " 'absco565': 'aerosol particle light absorption coefficient',\n",
       " 'absco590': 'aerosol particle light absorption coefficient',\n",
       " 'absco637': 'aerosol particle light absorption coefficient',\n",
       " 'absco652': 'aerosol particle light absorption coefficient',\n",
       " 'absco660': 'aerosol particle light absorption coefficient',\n",
       " 'absco670': 'aerosol particle light absorption coefficient',\n",
       " 'absco880': 'aerosol particle light absorption coefficient',\n",
       " 'absco950': 'aerosol particle light absorption coefficient',\n",
       " 'lbsco450': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco520': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco525': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco530': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco532': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco550': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco635': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco700': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lbsco850': 'aerosol particle light hemispheric backscatter coefficient',\n",
       " 'lsco450': 'aerosol particle light scattering coefficient',\n",
       " 'lsco520': 'aerosol particle light scattering coefficient',\n",
       " 'lsco525': 'aerosol particle light scattering coefficient',\n",
       " 'lsco530': 'aerosol particle light scattering coefficient',\n",
       " 'lsco532': 'aerosol particle light scattering coefficient',\n",
       " 'lsco550': 'aerosol particle light scattering coefficient',\n",
       " 'lsco635': 'aerosol particle light scattering coefficient',\n",
       " 'lsco700': 'aerosol particle light scattering coefficient',\n",
       " 'lsco850': 'aerosol particle light scattering coefficient',\n",
       " 'precal': 'precipitation aluminium mass concentration',\n",
       " 'precas': 'precipitation arsenic mass concentration',\n",
       " 'wetbap': 'deposition benzo(a)pyrene mass flux',\n",
       " 'precca': 'precipitation calcium mass concentration',\n",
       " 'preccd': 'precipitation cadmium mass concentration',\n",
       " 'preccl': 'precipitation chloride mass concentration ',\n",
       " 'preccobalt': 'precipitation cobalt mass concentration',\n",
       " 'preccr': 'precipitation chromium mass concentration',\n",
       " 'preccu': 'precipitation copper mass concentration',\n",
       " 'precfe': 'precipitation iron mass concentration ',\n",
       " 'prechg': 'precipitation mercury mass concentration',\n",
       " 'preck': 'precipitation potassium mass concentration',\n",
       " 'precmg': 'precipitation magnesium mass concentration',\n",
       " 'precmn': 'precipitation manganese mass concentration',\n",
       " 'precmsa': 'precipitation methanesulfonic acid mass concentration',\n",
       " 'precna': 'precipitation sodium mass concentration',\n",
       " 'precnh4': 'precipitation ammonium mass concentration',\n",
       " 'precni': 'precipitation nickel mass concentration ',\n",
       " 'precno3': 'precipitation nitrate mass concentration ',\n",
       " 'precpb': 'precipitation lead mass concentration',\n",
       " 'precse': 'precipitation selenium mass concentration',\n",
       " 'precso4': 'precipitation sulphate mass concentration ',\n",
       " 'precv': 'precipitation vanadium mass concentration ',\n",
       " 'preczn': 'precipitation zinc mass concentration',\n",
       " 'wetal': 'deposition aluminium mass flux ',\n",
       " 'wetas': 'deposition arsenic mass flux',\n",
       " 'wetcd': 'deposition cadmium mass flux',\n",
       " 'wetcobalt': 'deposition cobalt mass flux',\n",
       " 'wetcr': 'deposition chromium mass flux',\n",
       " 'wetcu': 'deposition copper mass flux',\n",
       " 'wetfe': 'deposition iron mass flux',\n",
       " 'wethg': 'deposition mercury mass flux',\n",
       " 'wetmn': 'deposition manganese mass flux',\n",
       " 'wetpb': 'deposition lead mass flux',\n",
       " 'wetv': 'deposition vanadium mass flux',\n",
       " 'wetzn': 'deposition zinc mass flux',\n",
       " 't2': 'air temperature',\n",
       " 'pshltr': 'air pressure',\n",
       " 'acprec': 'precipitation depth',\n",
       " 'od380aero': 'aerosol particle optical depth',\n",
       " 'od440aero': 'aerosol particle optical depth',\n",
       " 'od500aero': 'aerosol particle optical depth',\n",
       " 'od550aero': 'aerosol particle optical depth',\n",
       " 'od675aero': 'aerosol particle optical depth',\n",
       " 'od870aero': 'aerosol particle optical depth',\n",
       " 'od1020aero': 'aerosol particle optical depth'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters_dict = {}\n",
    "with open('ghost_actris_variables.csv', mode='r', encoding='utf-8') as file:\n",
    "    reader = csv.reader(file)\n",
    "    for row in reader:\n",
    "        # if ACTRIS was found (manual intervention)\n",
    "        if len(row[6]) != 0 and row[6] != 'Preferred':\n",
    "            # 'Preferred' = 'BSC'\n",
    "            parameters_dict[row[1]] = row[6]\n",
    "parameters_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd098d0-b432-4e4d-8259-bf99ff678b61",
   "metadata": {},
   "source": [
    "# Get BSC-ACTRIS metadata dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61b59fb2-f770-4ba5-aba9-b000256e8283",
   "metadata": {},
   "outputs": [],
   "source": [
    "standard_metadata = get_standard_metadata({'standard_units': ''})\n",
    "ghost_metadata = list(standard_metadata.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b650d39-fa05-497b-b6eb-66d2b9142d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "actris_metadata = ['Conventions', 'featureType', 'title', 'keywords', 'id', 'naming_authority',\n",
    "                   'project', 'acknowledgement', 'doi', 'license', 'citation', 'summary', 'source', \n",
    "                   'institution', 'processing_level', 'date_created', 'date_metadata_modified', \n",
    "                   'creator_name', 'creator_type', 'creator_email', 'creator_institution',\n",
    "                   'contributor_name', 'contributor_role', 'publisher_type', 'publisher_name', \n",
    "                   'publisher_institution', 'publisher_email', 'publisher_url', 'geospatial_bounds', \n",
    "                   'geospatial_bounds_crs', 'geospatial_lat_min', 'geospatial_lat_max',\n",
    "                   'geospatial_lon_min', 'geospatial_lon_max', 'geospatial_vertical_min', \n",
    "                   'geospatial_vertical_max', 'geospatial_vertical_positive', 'time_coverage_start',\n",
    "                   'time_coverage_end', 'time_coverage_duration', 'time_coverage_resolution',\n",
    "                   'timezone', 'ebas_data_definition', 'ebas_data_license', 'ebas_citation', \n",
    "                   'ebas_set_type_code', 'ebas_timezone', 'ebas_file_name', 'ebas_represents_doi',\n",
    "                   'ebas_contains_doi', 'ebas_file_creation', 'ebas_export_state', 'ebas_export_filter',\n",
    "                   'ebas_startdate', 'ebas_revision_date', 'ebas_data_level', 'ebas_period_code',\n",
    "                   'ebas_resolution_code', 'ebas_sample_duration', 'ebas_orig_time_res',\n",
    "                   'ebas_station_code', 'ebas_platform_code', 'ebas_station_name', \n",
    "                   'ebas_station_wdca_id', 'ebas_station_gaw_id', 'ebas_station_gaw_name',\n",
    "                   'ebas_station_land_use', 'ebas_station_setting', 'ebas_station_gaw_type', \n",
    "                   'ebas_station_wmo_region', 'ebas_station_latitude', 'ebas_station_longitude', \n",
    "                   'ebas_station_altitude', 'ebas_measurement_height', 'ebas_regime', 'ebas_component',\n",
    "                   'ebas_matrix', 'ebas_laboratory_code', 'ebas_instrument_type', 'ebas_instrument_name',\n",
    "                   'ebas_instrument_manufacturer', 'ebas_instrument_model', \n",
    "                   'ebas_instrument_serial_number', 'ebas_method_ref', 'ebas_standard_method',\n",
    "                   'ebas_inlet_type', 'ebas_inlet_description', 'ebas_humidity_temperaure_control',\n",
    "                   'ebas_absorption_cross_section', 'ebas_organization', 'ebas_framework_acronym',\n",
    "                   'ebas_framework_name', 'ebas_framework_description', 'ebas_framework_contact_name',\n",
    "                   'ebas_framework_contact_email', 'ebas_originator', 'ebas_submitter', \n",
    "                   'ebas_acknowledgement', 'Metadata_Conventions', 'geospatial_lat_units', \n",
    "                   'geospatial_lon_units', 'comment', 'standard_name_vocabulary', 'history', \n",
    "                   'creator_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8bb43695-27c9-40ae-a283-a94a761fdacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metadata_dict = {'station_reference': 'ebas_station_code',\n",
    "                     'WIGOS_station_identifier': '',\n",
    "                     'station_timezone': 'timezone',\n",
    "                     'latitude': 'ebas_station_latitude',\n",
    "                     'longitude': 'ebas_station_longitude',\n",
    "                     'altitude': 'ebas_station_altitude',\n",
    "                     'sampling_height': 'ebas_measurement_height',\n",
    "                     'measurement_altitude': 'ebas_station_altitude', # no diff with altitude?\n",
    "                     'ellipsoid': '',\n",
    "                     'horizontal_datum': '',\n",
    "                     'vertical_datum': '',\n",
    "                     'projection': '',\n",
    "                     'distance_to_building': '',\n",
    "                     'distance_to_kerb': '',\n",
    "                     'distance_to_junction': '',\n",
    "                     'distance_to_source': '',\n",
    "                     'street_width': '',\n",
    "                     'street_type': '',\n",
    "                     'daytime_traffic_speed': '',\n",
    "                     'daily_passing_vehicles': '',\n",
    "                     'data_level': 'ebas_data_level',\n",
    "                     'climatology': '',\n",
    "                     'station_name': 'ebas_station_name',\n",
    "                     'city': '', # get from title\n",
    "                     'country': '',\n",
    "                     'administrative_country_division_1': '',\n",
    "                     'administrative_country_division_2': '',\n",
    "                     'population': '',\n",
    "                     'representative_radius': '',\n",
    "                     'network': 'naming_authority',\n",
    "                     'associated_networks': 'naming_authority',\n",
    "                     'area_classification': '',\n",
    "                     'station_classification': '',\n",
    "                     'main_emission_source': '',\n",
    "                     'land_use': 'ebas_station_land_use',\n",
    "                     'terrain': '',\n",
    "                     'measurement_scale': '',\n",
    "                     'ESDAC_Iwahashi_landform_classification': '',\n",
    "                     'ESDAC_modal_Iwahashi_landform_classification_5km': '',\n",
    "                     'ESDAC_modal_Iwahashi_landform_classification_25km': '',\n",
    "                     'ESDAC_Meybeck_landform_classification': '',\n",
    "                     'ESDAC_modal_Meybeck_landform_classification_5km': '',\n",
    "                     'ESDAC_modal_Meybeck_landform_classification_25km': '',\n",
    "                     'GHSL_settlement_model_classification': '',\n",
    "                     'GHSL_modal_settlement_model_classification_5km': '',\n",
    "                     'GHSL_modal_settlement_model_classification_25km': '',\n",
    "                     'Joly-Peuch_classification_code': '',\n",
    "                     'Koppen-Geiger_classification': '',\n",
    "                     'Koppen-Geiger_modal_classification_5km': '',\n",
    "                     'Koppen-Geiger_modal_classification_25km': '',\n",
    "                     'MODIS_MCD12C1_v6_IGBP_land_use': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_IGBP_land_use_5km': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_IGBP_land_use_25km': '',\n",
    "                     'MODIS_MCD12C1_v6_UMD_land_use': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_UMD_land_use_5km': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_UMD_land_use_25km': '',\n",
    "                     'MODIS_MCD12C1_v6_LAI': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_LAI_5km': '',\n",
    "                     'MODIS_MCD12C1_v6_modal_LAI_25km': '',\n",
    "                     'WMO_region': 'ebas_station_wmo_region',\n",
    "                     'WWF_TEOW_terrestrial_ecoregion': '',\n",
    "                     'WWF_TEOW_biogeographical_realm': '',\n",
    "                     'WWF_TEOW_biome': '',\n",
    "                     'UMBC_anthrome_classification': '',\n",
    "                     'UMBC_modal_anthrome_classification_5km': '',\n",
    "                     'UMBC_modal_anthrome_classification_25km': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_BC_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_CO_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_NH3_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_NMVOC_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_NOx_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_OC_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_PM10_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_biogenic_PM2.5_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_fossilfuel_PM2.5_emissions': '',\n",
    "                     'EDGAR_v4.3.2_annual_average_SO2_emissions': '',\n",
    "                     'ASTER_v3_altitude': '',\n",
    "                     'ETOPO1_altitude': '',\n",
    "                     'ETOPO1_max_altitude_difference_5km': '',\n",
    "                     'GHSL_built_up_area_density': '',\n",
    "                     'GHSL_average_built_up_area_density_5km': '',\n",
    "                     'GHSL_average_built_up_area_density_25km': '',\n",
    "                     'GHSL_max_built_up_area_density_5km': '',\n",
    "                     'GHSL_max_built_up_area_density_25km': '',\n",
    "                     'GHSL_population_density': '',\n",
    "                     'GHSL_average_population_density_5km': '',\n",
    "                     'GHSL_average_population_density_25km': '',\n",
    "                     'GHSL_max_population_density_5km': '',\n",
    "                     'GHSL_max_population_density_25km': '',\n",
    "                     'GPW_population_density': '',\n",
    "                     'GPW_average_population_density_5km': '',\n",
    "                     'GPW_average_population_density_25km': '',\n",
    "                     'GPW_max_population_density_5km': '',\n",
    "                     'GPW_max_population_density_25km': '',\n",
    "                     'NOAA-DMSP-OLS_v4_nighttime_stable_lights': '',\n",
    "                     'NOAA-DMSP-OLS_v4_average_nighttime_stable_lights_5km': '',\n",
    "                     'NOAA-DMSP-OLS_v4_average_nighttime_stable_lights_25km': '',\n",
    "                     'NOAA-DMSP-OLS_v4_max_nighttime_stable_lights_5km': '',\n",
    "                     'NOAA-DMSP-OLS_v4_max_nighttime_stable_lights_25km': '',\n",
    "                     'OMI_level3_column_annual_average_NO2': '',\n",
    "                     'OMI_level3_column_cloud_screened_annual_average_NO2': '',\n",
    "                     'OMI_level3_tropospheric_column_annual_average_NO2': '',\n",
    "                     'OMI_level3_tropospheric_column_cloud_screened_annual_average_NO2': '',\n",
    "                     'GSFC_coastline_proximity': '',\n",
    "                     'primary_sampling_type': '',\n",
    "                     'primary_sampling_instrument_name': '',\n",
    "                     'primary_sampling_instrument_documented_flow_rate': '',\n",
    "                     'primary_sampling_instrument_reported_flow_rate': '',\n",
    "                     'primary_sampling_process_details': '',\n",
    "                     'primary_sampling_instrument_manual_name': '',\n",
    "                     'primary_sampling_further_details': '',\n",
    "                     'sample_preparation_types': '',\n",
    "                     'sample_preparation_techniques': '',\n",
    "                     'sample_preparation_process_details': '',\n",
    "                     'sample_preparation_further_details': '',\n",
    "                     'measurement_methodology': 'ebas_method_ref',\n",
    "                     'measuring_instrument_name': 'ebas_instrument_name',\n",
    "                     'measuring_instrument_sampling_type': 'ebas_instrument_type',\n",
    "                     'measuring_instrument_documented_flow_rate': '',\n",
    "                     'measuring_instrument_reported_flow_rate': '',\n",
    "                     'measuring_instrument_process_details': '',\n",
    "                     'measuring_instrument_manual_name': '',\n",
    "                     'measuring_instrument_further_details': '',\n",
    "                     'measuring_instrument_reported_units': '',\n",
    "                     'measuring_instrument_reported_lower_limit_of_detection': '',\n",
    "                     'measuring_instrument_documented_lower_limit_of_detection': '',\n",
    "                     'measuring_instrument_reported_upper_limit_of_detection': '',\n",
    "                     'measuring_instrument_documented_upper_limit_of_detection': '',\n",
    "                     'measuring_instrument_reported_uncertainty': '',\n",
    "                     'measuring_instrument_documented_uncertainty': '',\n",
    "                     'measuring_instrument_reported_accuracy': '',\n",
    "                     'measuring_instrument_documented_accuracy': '',\n",
    "                     'measuring_instrument_reported_precision': '',\n",
    "                     'measuring_instrument_documented_precision': '',\n",
    "                     'measuring_instrument_reported_zero_drift': '',\n",
    "                     'measuring_instrument_documented_zero_drift': '',\n",
    "                     'measuring_instrument_reported_span_drift': '',\n",
    "                     'measuring_instrument_documented_span_drift': '',\n",
    "                     'measuring_instrument_reported_zonal_drift': '',\n",
    "                     'measuring_instrument_documented_zonal_drift': '',\n",
    "                     'measuring_instrument_reported_measurement_resolution': '',\n",
    "                     'measuring_instrument_documented_measurement_resolution': '',\n",
    "                     'measuring_instrument_reported_absorption_cross_section': '',\n",
    "                     'measuring_instrument_documented_absorption_cross_section': '',\n",
    "                     'measuring_instrument_inlet_information': 'ebas_inlet_description',\n",
    "                     'measuring_instrument_calibration_scale': '',\n",
    "                     'network_provided_volume_standard_temperature': '',\n",
    "                     'network_provided_volume_standard_pressure': '',\n",
    "                     'retrieval_algorithm': '',\n",
    "                     'principal_investigator_name': 'creator_name',\n",
    "                     'principal_investigator_institution': 'creator_institution',\n",
    "                     'principal_investigator_email_address': 'creator_email',\n",
    "                     'contact_name': 'publisher_name', # TODO: in doubt\n",
    "                     'contact_institution': 'publisher_institution', # TODO: in doubt\n",
    "                     'contact_email_address': 'publisher_email', # TODO: in doubt\n",
    "                     'meta_update_stamp': 'date_metadata_modified',\n",
    "                     'data_download_stamp': '', # TODO: Do we put our download date here?\n",
    "                     'data_revision_stamp': '',\n",
    "                     'network_sampling_details': '',\n",
    "                     'network_uncertainty_details': '',\n",
    "                     'network_maintenance_details': '',\n",
    "                     'network_qa_details': '',\n",
    "                     'network_miscellaneous_details': '',\n",
    "                     'data_licence': 'license',\n",
    "                     'process_warnings': ''}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7909442a-f3c0-47f4-b514-85840a0a9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'station_reference': 'ebas_station_code',\n",
       " 'station_timezone': 'timezone',\n",
       " 'latitude': 'ebas_station_latitude',\n",
       " 'longitude': 'ebas_station_longitude',\n",
       " 'altitude': 'ebas_station_altitude',\n",
       " 'sampling_height': 'ebas_measurement_height',\n",
       " 'measurement_altitude': 'ebas_station_altitude',\n",
       " 'data_level': 'ebas_data_level',\n",
       " 'station_name': 'ebas_station_name',\n",
       " 'network': 'naming_authority',\n",
       " 'associated_networks': 'naming_authority',\n",
       " 'land_use': 'ebas_station_land_use',\n",
       " 'WMO_region': 'ebas_station_wmo_region',\n",
       " 'measurement_methodology': 'ebas_method_ref',\n",
       " 'measuring_instrument_name': 'ebas_instrument_name',\n",
       " 'measuring_instrument_sampling_type': 'ebas_instrument_type',\n",
       " 'measuring_instrument_inlet_information': 'ebas_inlet_description',\n",
       " 'principal_investigator_name': 'creator_name',\n",
       " 'principal_investigator_institution': 'creator_institution',\n",
       " 'principal_investigator_email_address': 'creator_email',\n",
       " 'contact_name': 'publisher_name',\n",
       " 'contact_institution': 'publisher_institution',\n",
       " 'contact_email_address': 'publisher_email',\n",
       " 'meta_update_stamp': 'date_metadata_modified',\n",
       " 'data_licence': 'license'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_dict = {k: v for k, v in all_metadata_dict.items() if v != ''}\n",
    "metadata_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58faeaba-c27c-4a5c-a114-f0f35131c508",
   "metadata": {},
   "source": [
    "# Get files per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3592c2f7-7032-448b-af96-54a1caac42ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_per_variable(chunk_i, variables):\n",
    "    files_per_var = {}\n",
    "    base_url = \"https://prod-actris-md.nilu.no/metadata/content\"\n",
    "    n_variables = len(variables)\n",
    "    print('Variables:', variables)\n",
    "    for var_i, var in enumerate(variables):\n",
    "        print(f'[{chunk_i}] {var} ({var_i}/{n_variables})')\n",
    "        if var not in files_per_var:\n",
    "            files_per_var[var] = {}\n",
    "        variable_files = []\n",
    "        page = 0\n",
    "        while True:\n",
    "            # Set up URL with pagination\n",
    "            url = f\"{base_url}/{parameters_dict[var]}/page/{page}\"\n",
    "            response = requests.get(url)\n",
    "            \n",
    "            # Check if the response is valid and contains data\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Error fetching page {page}. Status code: {response.status_code}\")\n",
    "                break\n",
    "            \n",
    "            data = response.json()\n",
    "            \n",
    "            # Check if there's content in the data\n",
    "            if not data:\n",
    "                break\n",
    "            \n",
    "            # Loop through each entry in the data and print DOI and OPeNDAP URL\n",
    "            for item in data:\n",
    "                doi = item.get(\"md_identification\", {}).get(\"identifier\", {}).get(\"pid\")\n",
    "                opendap_urls = [protocol_dict['dataset_url'] for protocol_dict in item.get('md_distribution_information', []) if protocol_dict.get('protocol') == 'OPeNDAP']\n",
    "                \n",
    "                # Print DOI and OPeNDAP URL if both are present\n",
    "                if doi and opendap_urls:\n",
    "                    variable_files.append(opendap_urls)\n",
    "                    \n",
    "            # Go to the next page\n",
    "            page += 1\n",
    "        \n",
    "        files_per_var[var]['files'] = list(itertools.chain.from_iterable(variable_files))\n",
    "    \n",
    "    return files_per_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22e078bf-ac27-4a5f-80d5-93c19a3c7311",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_per_var_list(variables):\n",
    "    combined_data = {}\n",
    "    chunk_size = 100\n",
    "    chunks = [list(variables)[i:i + chunk_size] for i in range(0, len(variables), chunk_size)]\n",
    "    for chunk_i, chunk in enumerate(chunks):\n",
    "        files_per_var = get_files_per_variable(chunk_i, chunk)\n",
    "        combined_data.update(files_per_var)\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "302cbce2-ae1a-49fe-9057-773eafce8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables: ['sconco3']\n",
      "[0] sconco3 (0/1)\n"
     ]
    }
   ],
   "source": [
    "combined_data = get_files_per_var_list(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e38cda4-7261-4b32-aaee-ec1bd4861dd2",
   "metadata": {},
   "source": [
    "# Get information on files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "38da7bf5-a662-4f82-b120-7065c0746e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files_info(var, files):\n",
    "\n",
    "    files_info = {}\n",
    "    files_info[var] = {}\n",
    "    for i, file in enumerate(files):\n",
    "        print(f'{i} - {file}')\n",
    "        try:\n",
    "            ds = xr.open_dataset(file)\n",
    "        except:\n",
    "            print('Error opening dataset')\n",
    "            continue\n",
    "        coverage = ds.time_coverage_resolution\n",
    "        try:             \n",
    "            file_resolution = coverages_dict[coverage]\n",
    "        except:\n",
    "            print('Error in resolution with coverage:', coverage)\n",
    "            continue\n",
    "        start_date = ds.time_coverage_start\n",
    "        end_date = ds.time_coverage_end\n",
    "        variables = list(ds.data_vars.keys())\n",
    "        files_info[var][file] = {}\n",
    "        files_info[var][file]['resolution'] = file_resolution\n",
    "        files_info[var][file]['start_date'] = start_date\n",
    "        files_info[var][file]['end_date'] = end_date\n",
    "        files_info[var][file]['variables'] = variables\n",
    "\n",
    "    return files_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "758bea82-74da-41da-a4cd-13455cb67930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File files/sconco3/files.yaml already exists, checking if it needs an update.\n",
      "- Files to add (17): ['https://thredds.nilu.no/thredds/dodsC/ebas_doi/NM/W2/TX/NMW2-TXB2.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/NK/5T/S8/NK5T-S833.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/N6/3K/2U/N63K-2UAD.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/U4/78/WA/U478-WAZD.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/2P/E8/8F/2PE8-8FAN.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/9U/DF/CK/9UDF-CKQX.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/RF/84/TH/RF84-THM7.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/7G/2P/US/7G2P-USM4.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/AM/E9/9E/AME9-9EGX.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/UR/GM/TW/URGM-TWSA.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/W8/F6/KY/W8F6-KYTE.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/4X/UY/XX/4XUY-XX66.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/P5/BS/GW/P5BS-GWDW.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/SE/D6/56/SED6-5637.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/PS/FE/4U/PSFE-4UXV.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/35/DD/E2/35DD-E28C.nc', 'https://thredds.nilu.no/thredds/dodsC/ebas_doi/8Q/2P/Y2/8Q2P-Y2Z4.nc']\n",
      "Getting information...\n",
      "0 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NM/W2/TX/NMW2-TXB2.nc\n",
      "Error opening dataset\n",
      "1 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NK/5T/S8/NK5T-S833.nc\n",
      "Error opening dataset\n",
      "2 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/N6/3K/2U/N63K-2UAD.nc\n",
      "Error opening dataset\n",
      "3 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/U4/78/WA/U478-WAZD.nc\n",
      "Error opening dataset\n",
      "4 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2P/E8/8F/2PE8-8FAN.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "5 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/9U/DF/CK/9UDF-CKQX.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "6 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RF/84/TH/RF84-THM7.nc\n",
      "Error opening dataset\n",
      "7 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/7G/2P/US/7G2P-USM4.nc\n",
      "Error opening dataset\n",
      "8 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AM/E9/9E/AME9-9EGX.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "9 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/UR/GM/TW/URGM-TWSA.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "10 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/W8/F6/KY/W8F6-KYTE.nc\n",
      "Error opening dataset\n",
      "11 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4X/UY/XX/4XUY-XX66.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "12 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/P5/BS/GW/P5BS-GWDW.nc\n",
      "Error opening dataset\n",
      "13 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SE/D6/56/SED6-5637.nc\n",
      "Error opening dataset\n",
      "14 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PS/FE/4U/PSFE-4UXV.nc\n",
      "Error opening dataset\n",
      "15 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/35/DD/E2/35DD-E28C.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "16 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8Q/2P/Y2/8Q2P-Y2Z4.nc\n",
      "Error in resolution with coverage: P0000-00-00T00:00:00\n",
      "No relevant changes were found.\n",
      "CPU times: user 887 ms, sys: 44.8 ms, total: 932 ms\n",
      "Wall time: 6.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for var in variables:\n",
    "    path = f'files/{var}/files.yaml'\n",
    "    # if file does not exist\n",
    "    if not os.path.isfile(path):\n",
    "\n",
    "        print(f'File {path} does not exist, creating.')\n",
    "\n",
    "        # get files information\n",
    "        files = combined_data[var]['files']\n",
    "        print('Total number of files:', len(files))\n",
    "        print('Getting information...')\n",
    "        files_info = get_files_info(var, files)\n",
    "    \n",
    "        # create file\n",
    "        datasets = {\n",
    "            url: data\n",
    "            for url, data in files_info[var].items()\n",
    "        }\n",
    "        if len(datasets) != 0:\n",
    "            path_dir = os.path.dirname(path)\n",
    "            if not os.path.exists(path_dir):\n",
    "                os.makedirs(path_dir)\n",
    "            with open(path, 'w') as file:\n",
    "                yaml.dump(datasets, file, default_flow_style=False)\n",
    "            \n",
    "    # if file exists\n",
    "    else:\n",
    "        print(f'File {path} already exists, checking if it needs an update.')\n",
    "        \n",
    "        # get currently available files\n",
    "        current_files = combined_data[var]['files']\n",
    "    \n",
    "        # get previously saved files\n",
    "        file_info_to_update = yaml.safe_load(open(os.path.join(CURRENT_PATH, path)))\n",
    "        previous_files = list(file_info_to_update.keys())\n",
    "\n",
    "        # keep old files only if they are currently available\n",
    "        files_to_remove = []\n",
    "        for file in previous_files:\n",
    "            if file not in current_files:\n",
    "                files_to_remove.append(file)\n",
    "    \n",
    "        # add new files\n",
    "        files_to_add = []\n",
    "        for file in current_files:\n",
    "            if file not in previous_files:\n",
    "                files_to_add.append(file)\n",
    "\n",
    "        # get information from new files\n",
    "        if len(files_to_add) > 0:\n",
    "            print('- Files to add ({0}): {1}'.format(len(files_to_add), files_to_add))\n",
    "            print('Getting information...')\n",
    "            files_info = get_files_info(var, files_to_add)\n",
    "            datasets = {\n",
    "                url: data\n",
    "                for url, data in files_info[var].items()\n",
    "            }\n",
    "    \n",
    "            # add new data to dictionary\n",
    "            if len(datasets) != 0:\n",
    "                file_info_to_update.update(datasets)\n",
    "    \n",
    "        # remove unavailable data\n",
    "        if len(files_to_remove) > 0:\n",
    "            print('- Files to remove ({0}): {1}'.format(len(files_to_remove), files_to_remove))\n",
    "            for file in files_to_remove:\n",
    "                print(f'Removing file {file}')\n",
    "                file_info_to_update.pop(file, None)\n",
    "    \n",
    "        # recreate file info \n",
    "        if len(datasets) != 0 or len(files_to_remove) > 0:\n",
    "            print('Updating file...')\n",
    "            os.remove(path)\n",
    "            with open(path, 'w') as file:\n",
    "                yaml.dump(file_info_to_update, file, default_flow_style=False)\n",
    "        else:\n",
    "            print('No relevant changes were found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abef46b1-9006-4071-b102-6f96f593e7eb",
   "metadata": {},
   "source": [
    "# Format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5592bd67-9cae-4875-b46b-1003453d3d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_files(var, resolution, target_start_date, target_end_date):\n",
    "    files = []\n",
    "    files_info = yaml.safe_load(open(os.path.join(CURRENT_PATH, f'files/{var}/files.yaml')))\n",
    "    files_info = {k: v for k, v in files_info.items() if k.strip() and v}\n",
    "    for file, attributes in files_info.items():\n",
    "        if attributes[\"resolution\"] == resolution:\n",
    "            start_date = datetime.datetime.strptime(attributes[\"start_date\"], \"%Y-%m-%dT%H:%M:%S UTC\")\n",
    "            end_date = datetime.datetime.strptime(attributes[\"end_date\"], \"%Y-%m-%dT%H:%M:%S UTC\")\n",
    "            if start_date <= target_end_date and end_date >= target_start_date:\n",
    "                files.append(file)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e5522c38-5f19-4056-91e3-4ecb251364cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporally_average_data(combined_ds, year, month, var):\n",
    "\n",
    "    # get valid dates frequency\n",
    "    if resolution == 'hourly':\n",
    "        frequency = 'h'\n",
    "    elif resolution == 'daily':\n",
    "        frequency = 'D'\n",
    "    elif resolution == 'monthly':\n",
    "        frequency = 'MS'\n",
    "\n",
    "    # get start and end of period to construct valid dates\n",
    "    time = combined_ds.time.values\n",
    "    start_date = datetime.datetime(year, month, 1)\n",
    "    first_day_next_month = datetime.datetime(year, month % 12 + 1, 1) if month != 12 else datetime.datetime(year + 1, 1, 1)\n",
    "    end_date = first_day_next_month - datetime.timedelta(days=1)\n",
    "    valid_dates = pd.date_range(start=start_date, end=end_date, freq=frequency).to_numpy(dtype='datetime64[ns]')\n",
    "    \n",
    "    # initialise averaged data\n",
    "    averaged_data = np.empty((len(combined_ds.station.values), len(valid_dates)))\n",
    "    \n",
    "    for station_i, station in enumerate(combined_ds.station.values):\n",
    "        # initialise averaged data\n",
    "        station_averaged_data = []\n",
    "    \n",
    "        # read data per station\n",
    "        data = combined_ds[var].isel(station=station_i).values\n",
    "\n",
    "        # ignore data (times and values) if the values are nan\n",
    "        valid_idxs = ~np.isnan(data)\n",
    "        valid_time = time[valid_idxs]\n",
    "        valid_data = data[valid_idxs]\n",
    "\n",
    "        # calculate weighted averages\n",
    "        if len(valid_data) != 0:\n",
    "            for date in valid_dates:\n",
    "            \n",
    "                # get differences between valid time and actual times in minutes\n",
    "                time_diffs = (valid_time - date).astype('timedelta64[ns]').astype(float)\n",
    "            \n",
    "                # get positive differences and negative differences to differentiate \n",
    "                # between the actual times that are earlier than the valid date (negative), and those that are later (positive)\n",
    "                positive_diffs = time_diffs[time_diffs > 0]\n",
    "                negative_diffs = time_diffs[time_diffs < 0]\n",
    "                \n",
    "                # find the closest actual time after the valid time\n",
    "                closest_positive = None\n",
    "                if len(positive_diffs) > 0:\n",
    "                    closest_positive_idx = np.abs(positive_diffs).argmin()\n",
    "                    closest_positive = positive_diffs[closest_positive_idx]\n",
    "                    closest_positive_time = valid_time[time_diffs == positive_diffs[closest_positive_idx]][0]\n",
    "                    closest_positive_value = valid_data[time_diffs == positive_diffs[closest_positive_idx]][0]\n",
    "            \n",
    "                # find the closest actual time before the valid time\n",
    "                closest_negative = None\n",
    "                if len(negative_diffs) > 0:\n",
    "                    closest_negative_idx = np.abs(negative_diffs).argmin()\n",
    "                    closest_negative = negative_diffs[closest_negative_idx]\n",
    "                    closest_negative_time = valid_time[time_diffs == negative_diffs[closest_negative_idx]][-1]\n",
    "                    closest_negative_value = valid_data[time_diffs == negative_diffs[closest_negative_idx]][-1]\n",
    "            \n",
    "                # when the valid time only has a value in one direction, get closest value without calculating weights\n",
    "                if closest_positive is None:\n",
    "                    value = closest_negative_value\n",
    "                elif closest_negative is None:\n",
    "                    value = closest_positive_value\n",
    "                # in the rest of cases, calculate weights of 2 closest values and make average\n",
    "                else:\n",
    "                    # get 2 closest times and make positive to be able to compare differences\n",
    "                    closest_diffs = np.abs([closest_negative, closest_positive])\n",
    "            \n",
    "                    # we do the reverse, since we want the differences in minutes to have a heavier weight if these are smaller (nearer the actual time)\n",
    "                    weights = 1 / closest_diffs\n",
    "                    \n",
    "                    # finally we normalize them to have values between 0 and 1\n",
    "                    weights_normalized = weights / np.sum(weights)\n",
    "            \n",
    "                    # get average\n",
    "                    value = np.average([closest_negative_value, closest_positive_value], weights=weights_normalized)\n",
    "        \n",
    "                # save averaged data\n",
    "                station_averaged_data.append(value)\n",
    "        \n",
    "            averaged_data[station_i, :] = station_averaged_data\n",
    "        else:\n",
    "            averaged_data[station_i, :] = [np.nan]*len(valid_dates)\n",
    "    \n",
    "    # create new variable with averaged data\n",
    "    combined_averaged_ds = xr.DataArray(\n",
    "        data=averaged_data,\n",
    "        coords={'station': combined_ds.station.values, 'time': valid_dates}, \n",
    "        dims=['station', 'time'],\n",
    "        attrs={'units': combined_ds[var].units})\n",
    "    \n",
    "    # drop old variable and associated time\n",
    "    combined_ds = combined_ds.drop_vars(var)\n",
    "    combined_ds = combined_ds.drop_dims('time')\n",
    "    \n",
    "    # add new variable\n",
    "    combined_ds[var] = combined_averaged_ds\n",
    "    \n",
    "    return combined_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541c4f6a-9d66-4ca7-9a57-084726e73824",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable: sconco3 - ACTRIS: ozone mass concentration\n",
      "Total number of files: 222\n",
      "0 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2F/57/5Y/2F57-5YWN.nc\n",
      "1 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2G/N5/BS/2GN5-BSG9.nc\n",
      "2 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2J/EC/FU/2JEC-FUND.nc\n",
      "3 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2M/DM/GF/2MDM-GFRA.nc\n",
      "4 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2Q/QE/CB/2QQE-CBAC.nc\n",
      "5 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/2R/WD/A6/2RWD-A6UJ.nc\n",
      "6 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3B/4H/V7/3B4H-V7QF.nc\n",
      "7 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3D/JD/E2/3DJD-E279.nc\n",
      "8 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3E/YC/7M/3EYC-7MNN.nc\n",
      "9 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3G/C7/QN/3GC7-QNSG.nc\n",
      "10 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3H/34/NS/3H34-NS7R.nc\n",
      "11 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3H/5X/DG/3H5X-DG99.nc\n",
      "12 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3P/9Z/6G/3P9Z-6GSC.nc\n",
      "13 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3V/T9/4N/3VT9-4NYV.nc\n",
      "14 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/3X/7Y/EB/3X7Y-EBHG.nc\n",
      "15 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/43/YG/9P/43YG-9PRC.nc\n",
      "16 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4D/AC/TN/4DAC-TNTS.nc\n",
      "17 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4K/3X/MQ/4K3X-MQ9B.nc\n",
      "18 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4R/WJ/WD/4RWJ-WDVE.nc\n",
      "19 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4W/T4/QY/4WT4-QYMR.nc\n",
      "20 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4W/VZ/3U/4WVZ-3U62.nc\n",
      "21 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/4X/XV/KX/4XXV-KX7N.nc\n",
      "22 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/5J/EN/Y2/5JEN-Y2RJ.nc\n",
      "23 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/5S/E4/H9/5SE4-H9UW.nc\n",
      "24 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/5T/E7/YV/5TE7-YVXP.nc\n",
      "25 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/5Z/8E/VZ/5Z8E-VZRU.nc\n",
      "26 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/5Z/KT/7N/5ZKT-7NEA.nc\n",
      "27 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6E/6P/N6/6E6P-N6P2.nc\n",
      "28 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6F/E3/MN/6FE3-MNQZ.nc\n",
      "29 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6P/CD/H8/6PCD-H87Q.nc\n",
      "30 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6P/FR/K8/6PFR-K8UK.nc\n",
      "31 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6U/MT/44/6UMT-44C3.nc\n",
      "32 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6X/87/F9/6X87-F9BX.nc\n",
      "33 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/6Y/AF/FW/6YAF-FWUB.nc\n",
      "34 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/75/QM/QM/75QM-QMAK.nc\n",
      "35 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/7G/CV/S7/7GCV-S74P.nc\n",
      "36 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/7J/27/DJ/7J27-DJ25.nc\n",
      "37 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/83/TA/ZC/83TA-ZCKC.nc\n",
      "38 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8D/JX/CY/8DJX-CYJ6.nc\n",
      "39 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8E/8E/W7/8E8E-W724.nc\n",
      "40 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8M/26/R8/8M26-R8CY.nc\n",
      "41 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8Q/JK/WG/8QJK-WGK7.nc\n",
      "42 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8S/QU/2D/8SQU-2DP9.nc\n",
      "43 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8V/WM/J6/8VWM-J68F.nc\n",
      "44 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8Z/QR/UR/8ZQR-URKE.nc\n",
      "45 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/8Z/SQ/9E/8ZSQ-9E5D.nc\n",
      "46 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/93/QJ/8B/93QJ-8BWH.nc\n",
      "47 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/95/JM/3P/95JM-3P3T.nc\n",
      "48 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/97/Q9/ST/97Q9-ST26.nc\n",
      "49 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/99/YT/22/99YT-22SX.nc\n",
      "50 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/A7/28/B7/A728-B77A.nc\n",
      "51 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AG/N8/AG/AGN8-AGQ5.nc\n",
      "52 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AG/T5/W8/AGT5-W8SW.nc\n",
      "53 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AM/YK/5Z/AMYK-5ZJ5.nc\n",
      "54 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AT/72/S4/AT72-S4QD.nc\n",
      "55 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/AV/TP/HW/AVTP-HWCX.nc\n",
      "56 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B2/QJ/6M/B2QJ-6MXB.nc\n",
      "57 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B3/6Y/39/B36Y-39YZ.nc\n",
      "58 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B4/2T/E5/B42T-E5K3.nc\n",
      "59 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B6/UC/VQ/B6UC-VQGT.nc\n",
      "60 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B6/UF/H4/B6UF-H4CS.nc\n",
      "61 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/B7/PR/WM/B7PR-WMKR.nc\n",
      "62 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/BD/MS/DH/BDMS-DHPN.nc\n",
      "63 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/BP/D5/N3/BPD5-N3P9.nc\n",
      "64 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/BR/SD/Q2/BRSD-Q2HE.nc\n",
      "65 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/C2/6V/JV/C26V-JV88.nc\n",
      "66 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/C6/JB/5Z/C6JB-5ZBE.nc\n",
      "67 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/C7/SC/ZJ/C7SC-ZJ9A.nc\n",
      "68 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CD/AA/K9/CDAA-K9ZN.nc\n",
      "69 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CN/SD/9X/CNSD-9X85.nc\n",
      "70 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CR/HM/3F/CRHM-3F32.nc\n",
      "71 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CS/KG/3B/CSKG-3BP2.nc\n",
      "72 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CT/2D/VC/CT2D-VC7Q.nc\n",
      "73 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CT/JJ/PU/CTJJ-PUNE.nc\n",
      "74 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CX/AQ/EW/CXAQ-EWYA.nc\n",
      "75 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/CX/VP/8N/CXVP-8NC7.nc\n",
      "76 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/DF/4X/W5/DF4X-W54N.nc\n",
      "77 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/DP/4J/XX/DP4J-XXFY.nc\n",
      "78 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/DP/P9/2A/DPP9-2A4G.nc\n",
      "79 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/DX/DP/5K/DXDP-5KBE.nc\n",
      "80 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/DZ/EF/JR/DZEF-JR6Q.nc\n",
      "81 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/E3/53/S4/E353-S4F3.nc\n",
      "82 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/E4/UG/EK/E4UG-EK4V.nc\n",
      "83 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/EB/U4/U2/EBU4-U2HK.nc\n",
      "84 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/EK/83/VS/EK83-VS9N.nc\n",
      "85 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/EQ/PA/CN/EQPA-CN99.nc\n",
      "86 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/ES/AQ/ZW/ESAQ-ZW2H.nc\n",
      "87 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/EW/J2/TJ/EWJ2-TJUP.nc\n",
      "88 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/F4/RU/JC/F4RU-JC5C.nc\n",
      "89 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FA/29/7W/FA29-7W8V.nc\n",
      "90 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FA/V7/UQ/FAV7-UQAN.nc\n",
      "91 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FD/KH/FS/FDKH-FSGM.nc\n",
      "92 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FJ/WX/88/FJWX-88GT.nc\n",
      "93 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FP/P4/CW/FPP4-CW6A.nc\n",
      "94 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FP/V4/BB/FPV4-BBDX.nc\n",
      "95 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FW/E8/Z5/FWE8-Z5W6.nc\n",
      "96 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FX/KW/V7/FXKW-V74Q.nc\n",
      "97 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/FY/63/5R/FY63-5R8W.nc\n",
      "98 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/G2/64/Q3/G264-Q3K5.nc\n",
      "99 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GC/YR/Z9/GCYR-Z9RV.nc\n",
      "100 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GH/6D/EZ/GH6D-EZ2E.nc\n",
      "101 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GM/ZM/55/GMZM-55AK.nc\n",
      "102 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GU/T7/DK/GUT7-DKSW.nc\n",
      "103 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GX/VM/B9/GXVM-B9D4.nc\n",
      "104 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/GY/WB/W2/GYWB-W2FB.nc\n",
      "105 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/H5/42/KK/H542-KK56.nc\n",
      "106 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/H8/WT/N2/H8WT-N2ZV.nc\n",
      "107 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/HE/2E/KA/HE2E-KAKQ.nc\n",
      "108 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/HF/9M/7U/HF9M-7UEQ.nc\n",
      "109 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/HG/26/DS/HG26-DSUN.nc\n",
      "110 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/HQ/RN/RP/HQRN-RPUJ.nc\n",
      "111 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/HW/VT/49/HWVT-49ZZ.nc\n",
      "112 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/JE/DP/6W/JEDP-6W8X.nc\n",
      "113 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/JH/8P/V4/JH8P-V4UY.nc\n",
      "114 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/JX/UE/PB/JXUE-PBXN.nc\n",
      "115 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/JY/WM/5P/JYWM-5P65.nc\n",
      "116 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/K2/2Z/MT/K22Z-MTXA.nc\n",
      "117 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/K2/9Z/6P/K29Z-6PPE.nc\n",
      "118 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/K4/U2/UE/K4U2-UE7Q.nc\n",
      "119 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/K6/XW/YZ/K6XW-YZR2.nc\n",
      "120 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/K7/H9/6Y/K7H9-6YVZ.nc\n",
      "121 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/KD/VN/C8/KDVN-C8U2.nc\n",
      "122 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/KF/PA/HF/KFPA-HFJH.nc\n",
      "123 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/KG/5M/VT/KG5M-VTPK.nc\n",
      "124 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/KR/HR/CS/KRHR-CSPH.nc\n",
      "125 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/KX/N8/UT/KXN8-UTSC.nc\n",
      "126 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/M3/ZY/JC/M3ZY-JCJG.nc\n",
      "127 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/M8/Z5/63/M8Z5-63QC.nc\n",
      "128 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MC/2X/6Z/MC2X-6ZFR.nc\n",
      "129 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MD/JG/SP/MDJG-SP28.nc\n",
      "130 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MJ/33/UU/MJ33-UUWD.nc\n",
      "131 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MK/63/8U/MK63-8U68.nc\n",
      "132 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MQ/UE/5M/MQUE-5MU9.nc\n",
      "133 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MV/AS/YR/MVAS-YR2P.nc\n",
      "134 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MY/MX/VC/MYMX-VCVC.nc\n",
      "135 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/MZ/BN/F9/MZBN-F9VK.nc\n",
      "136 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/N4/M9/GZ/N4M9-GZWB.nc\n",
      "137 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/N4/VF/T9/N4VF-T93E.nc\n",
      "138 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/N8/GB/GB/N8GB-GBNG.nc\n",
      "139 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NC/NA/ES/NCNA-ESQA.nc\n",
      "140 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NJ/JC/K8/NJJC-K8E7.nc\n",
      "141 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NJ/PH/QM/NJPH-QMH7.nc\n",
      "142 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NK/HE/8Q/NKHE-8QQU.nc\n",
      "143 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NS/38/VV/NS38-VVKD.nc\n",
      "144 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NS/Y6/WT/NSY6-WTT6.nc\n",
      "145 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NW/9Y/T4/NW9Y-T4T2.nc\n",
      "146 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NW/BY/VV/NWBY-VVQD.nc\n",
      "147 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/NX/94/KV/NX94-KVQH.nc\n",
      "148 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/P3/NZ/JR/P3NZ-JR85.nc\n",
      "149 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/P5/MT/KQ/P5MT-KQFV.nc\n",
      "150 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PF/JP/3U/PFJP-3UWQ.nc\n",
      "151 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PP/2Z/CJ/PP2Z-CJMY.nc\n",
      "152 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PS/GM/83/PSGM-83P2.nc\n",
      "153 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PV/D7/JZ/PVD7-JZ7M.nc\n",
      "154 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/PY/M7/CH/PYM7-CHMW.nc\n",
      "155 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/Q4/C6/9K/Q4C6-9KT9.nc\n",
      "156 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/Q7/CU/HX/Q7CU-HXY3.nc\n",
      "157 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/QA/8T/US/QA8T-USYY.nc\n",
      "158 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/QR/RT/5K/QRRT-5KP9.nc\n",
      "159 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/QT/MR/AZ/QTMR-AZ62.nc\n",
      "160 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/R2/KG/F9/R2KG-F9WM.nc\n",
      "161 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/R5/T2/BQ/R5T2-BQ47.nc\n",
      "162 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RA/X5/MQ/RAX5-MQ5E.nc\n",
      "163 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RB/5H/2X/RB5H-2XA5.nc\n",
      "164 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RC/NA/A6/RCNA-A6AZ.nc\n",
      "165 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RG/MG/9S/RGMG-9SAR.nc\n",
      "166 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RG/SZ/SJ/RGSZ-SJ33.nc\n",
      "167 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RJ/9X/S4/RJ9X-S4VZ.nc\n",
      "168 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RQ/SD/XM/RQSD-XM7D.nc\n",
      "169 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/RZ/NG/7X/RZNG-7XM3.nc\n",
      "170 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/S3/89/JQ/S389-JQAJ.nc\n",
      "171 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/S5/SF/9Q/S5SF-9QV6.nc\n",
      "172 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/S7/2Z/ET/S72Z-ETD8.nc\n",
      "173 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SA/W4/JC/SAW4-JCBD.nc\n",
      "174 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SH/5Q/GA/SH5Q-GA2K.nc\n",
      "175 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SV/XT/U3/SVXT-U3U8.nc\n",
      "176 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SY/CB/Q2/SYCB-Q2YD.nc\n",
      "177 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/SZ/JQ/H6/SZJQ-H6GJ.nc\n",
      "178 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/T2/AB/55/T2AB-55AK.nc\n",
      "179 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/T9/U5/MV/T9U5-MVAX.nc\n",
      "180 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/TJ/AC/8C/TJAC-8CG7.nc\n",
      "181 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/TK/TQ/RG/TKTQ-RGHT.nc\n",
      "182 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/TN/NM/VF/TNNM-VF46.nc\n",
      "183 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/U4/2S/MV/U42S-MVZB.nc\n",
      "184 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/U5/4Q/RY/U54Q-RY8X.nc\n",
      "185 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/UM/9B/EB/UM9B-EB74.nc\n",
      "186 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/UU/4W/3F/UU4W-3FBH.nc\n",
      "187 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/UV/XT/DJ/UVXT-DJDU.nc\n",
      "188 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/UY/3Y/7Y/UY3Y-7YFV.nc\n",
      "189 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/V2/FY/ZS/V2FY-ZSDN.nc\n",
      "190 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/VZ/EP/8C/VZEP-8CY7.nc\n",
      "191 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/W4/KF/YS/W4KF-YS67.nc\n",
      "192 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/WD/DN/PN/WDDN-PNF3.nc\n",
      "193 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/WG/G5/UX/WGG5-UXTA.nc\n",
      "194 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/WH/7C/GA/WH7C-GASF.nc\n",
      "195 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/WQ/N8/5S/WQN8-5SEU.nc\n",
      "196 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/WY/FM/YT/WYFM-YTHM.nc\n",
      "197 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/X7/XW/BV/X7XW-BVUJ.nc\n",
      "198 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/XB/4U/SG/XB4U-SGJW.nc\n",
      "199 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/XN/MP/6A/XNMP-6AAF.nc\n",
      "200 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/XQ/2E/TT/XQ2E-TTZ7.nc\n",
      "201 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/XR/W9/YJ/XRW9-YJWY.nc\n",
      "202 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/Y2/8Q/BD/Y28Q-BDEX.nc\n",
      "203 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/Y2/FC/6A/Y2FC-6ASZ.nc\n",
      "204 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/Y4/XB/WA/Y4XB-WAVE.nc\n",
      "205 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/YA/N5/YX/YAN5-YXBK.nc\n",
      "206 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/YE/6P/FY/YE6P-FYP3.nc\n",
      "207 - https://thredds.nilu.no/thredds/dodsC/ebas_doi/YE/TD/WS/YETD-WS9A.nc\n"
     ]
    }
   ],
   "source": [
    "for var in variables:\n",
    "    files = filter_files(var, resolution, target_start_date, target_end_date)\n",
    "    if len(files) != 0:\n",
    "    \n",
    "        actris_parameter = parameters_dict[var]\n",
    "        ebas_component = variable_mapping[actris_parameter]['var']\n",
    "        \n",
    "        print('Variable:', var, '- ACTRIS:', actris_parameter)\n",
    "        \n",
    "        # combine datasets that have the same variable and resolution\n",
    "        combined_ds_list = []\n",
    "        metadata = {}\n",
    "        metadata[resolution] = {}\n",
    "        \n",
    "        print('Total number of files:', len(files))\n",
    "        for i, file in enumerate(files):\n",
    "            print(i, '-', file)\n",
    "            # open file\n",
    "            try:\n",
    "                ds = xr.open_dataset(file)\n",
    "            except:\n",
    "                print('Error opening file')\n",
    "                continue\n",
    "\n",
    "            # get resolution\n",
    "            coverage = ds.time_coverage_resolution\n",
    "            resolution = coverages_dict[coverage]\n",
    "\n",
    "            # get lowest level if tower height is in coordinates\n",
    "            if 'Tower_inlet_height' in list(ds.coords):\n",
    "                ds = ds.sel(Tower_inlet_height=min(ds.Tower_inlet_height.values), drop=True)\n",
    "            \n",
    "            # assign station code as dimension\n",
    "            ds = ds.expand_dims(dim={'station': [i]})\n",
    "    \n",
    "            # select data for that variable only\n",
    "            unformatted_units = variable_mapping[actris_parameter]['units']\n",
    "            if unformatted_units in units_dict.keys():\n",
    "                units = units_dict[unformatted_units]\n",
    "            else:\n",
    "                print(f'Units {unformatted_units} were not found in dictionary')\n",
    "                continue\n",
    "            units_var = f'{ebas_component}_{units}'\n",
    "            possible_vars = [ebas_component, \n",
    "                             f'{ebas_component}_amean', \n",
    "                             units_var, \n",
    "                             f'{units_var}_amean']\n",
    "            ds_var_exists = False\n",
    "            for possible_var in possible_vars:\n",
    "                if possible_var in ds:\n",
    "                    ds_var = ds[possible_var]\n",
    "                    ds_var_exists = True\n",
    "                    break\n",
    "\n",
    "            # continue to next file if variable cannot be read\n",
    "            if not ds_var_exists:\n",
    "                print(f'No variable name matches for {possible_vars}. Existing keys: {list(ds.data_vars)}')\n",
    "                continue\n",
    "                \n",
    "            # save metadata\n",
    "            for ghost_key, ebas_key in metadata_dict.items():\n",
    "                # create key if it does not exist\n",
    "                if ghost_key not in metadata[resolution].keys():\n",
    "                    metadata[resolution][ghost_key] = []\n",
    "\n",
    "                # search value in var attrs\n",
    "                if ebas_key in ds_var.attrs.keys():\n",
    "                    metadata[resolution][ghost_key].append(ds_var.attrs[ebas_key])\n",
    "                # search value in ds attrs\n",
    "                elif ebas_key in ds.attrs.keys():\n",
    "                    metadata[resolution][ghost_key].append(ds.attrs[ebas_key])\n",
    "                # not found -> nan\n",
    "                else:\n",
    "                    metadata[resolution][ghost_key].append(np.nan)\n",
    "\n",
    "                        \n",
    "            # remove all attributes except units\n",
    "            ds_var.attrs = {key: value for key, value in ds_var.attrs.items() if key == 'units'}\n",
    "\n",
    "            # rename variable to BSC standards\n",
    "            ds_var = ds_var.to_dataset(name=var)\n",
    "\n",
    "            # append modified dataset to list\n",
    "            combined_ds_list.append(ds_var)\n",
    "\n",
    "        # combine and create new dataset\n",
    "        try:\n",
    "            combined_ds = xr.concat(combined_ds_list, \n",
    "                                    dim='station', \n",
    "                                    combine_attrs='drop_conflicts')\n",
    "        except Exception as error:\n",
    "            print(f'Error: Datasets could not be combined - {error}')\n",
    "            if 'time' in str(error):\n",
    "                for item in combined_ds_list:\n",
    "                    print(item.time.values[0], item.time.values[1])\n",
    "            continue\n",
    "        \n",
    "        # add metadata\n",
    "        for key, value in metadata[resolution].items():\n",
    "            if key in ['latitude', 'longitude']:\n",
    "                value = [float(val) for val in value]\n",
    "            elif key in ['altitude', 'measurement_altitude', 'sampling_height']:\n",
    "                value = [float(val.replace('m', '').strip()) if isinstance(val, str) else val for val in value]\n",
    "            combined_ds[key] = xr.Variable(data=value, dims=('station'))\n",
    "\n",
    "        # add units for lat and lon\n",
    "        # TODO: Check attrs geospatial_lat_units and geospatial_lon_units\n",
    "        combined_ds.latitude.attrs['units'] = 'degrees_north'\n",
    "        combined_ds.longitude.attrs['units'] = 'degrees_east'\n",
    "\n",
    "        # add general attrs\n",
    "        combined_ds.attrs['data_license'] = 'BSD-3-Clause. Copyright 2025 Alba Vilanova Cortezón'\n",
    "        combined_ds.attrs['source'] = 'Observations'\n",
    "        combined_ds.attrs['institution'] = 'Barcelona Supercomputing Center'\n",
    "        combined_ds.attrs['creator_name'] = 'Alba Vilanova Cortezón'\n",
    "        combined_ds.attrs['creator_email'] = 'alba.vilanova@bsc.es'\n",
    "        combined_ds.attrs['application_area'] = 'Monitoring atmospheric composition'\n",
    "        combined_ds.attrs['domain'] = 'Atmosphere'\n",
    "        combined_ds.attrs['observed_layer'] = 'Land surface'\n",
    "        \n",
    "        # save data per year and month\n",
    "        path = f'/home/avilanov/data/providentia/obs/nonghost/actris/actris/{resolution}/{var}'\n",
    "        if not os.path.isdir(path):\n",
    "            os.makedirs(path, exist_ok=True)\n",
    "        for year, ds_year in combined_ds.groupby('time.year'):\n",
    "            for month, ds_month in ds_year.groupby('time.month'):\n",
    "                if target_start_date <= datetime.datetime(year, month, 1) <= target_end_date:\n",
    "                    filename = f\"{path}/{var}_{year}{month:02d}.nc\"\n",
    "                    combined_ds_yearmonth = combined_ds.sel(time=f\"{year}-{month:02d}\")\n",
    "                    combined_ds_yearmonth = temporally_average_data(combined_ds_yearmonth, year, month, var)\n",
    "\n",
    "                    # add title to attrs\n",
    "                    combined_ds_yearmonth.attrs['title'] = f'Surface {parameters_dict[var]} in the ACTRIS network in {year}-{month:02d}.'\n",
    "\n",
    "                    # order attrs\n",
    "                    custom_order = ['title', 'institution', 'creator_name', 'creator_email',\n",
    "                                    'source', 'application_area', 'domain', 'observed_layer',\n",
    "                                    'data_license']\n",
    "                    ordered_attrs = {key: combined_ds_yearmonth.attrs[key] \n",
    "                                     for key in custom_order \n",
    "                                     if key in combined_ds_yearmonth.attrs}\n",
    "                    combined_ds_yearmonth.attrs = ordered_attrs\n",
    "\n",
    "                    # save file\n",
    "                    combined_ds_yearmonth.to_netcdf(filename)\n",
    "\n",
    "                    # change permissions\n",
    "                    os.system(\"chmod 775 {}\".format(filename))\n",
    "                    print(f\"Saved: {filename}\")\n",
    "\n",
    "    else:\n",
    "        print(f'No files were found for {var} in {resolution} resolution between {target_start_date} and {target_end_date}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdebd974-97e4-4346-b915-3ba6c73ae779",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f51ed7b-825e-4f30-9ea1-2ddb4547a9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = end_time - start_time\n",
    "total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2cd513-f0d2-4ba2-8c3a-0b341814c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "time.strftime(\"%H:%M:%S.{}\".format(str(total_time % 1)[2:])[:15], time.gmtime(total_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702e54a2-e5ad-422a-bd72-0ccb383c557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = xr.open_dataset(f'/home/avilanov/data/providentia/obs/nonghost/actris/actris/{resolution}/{var}/{var}_201801.nc')\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db987fc-8df5-4ab1-b6f0-428ae6b457b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonghost_data = xr.open_dataset('/home/avilanov/data/providentia/obs/nonghost/eea/eionet/hourly/sconcno2/sconcno2_202406.nc')\n",
    "nonghost_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1cdd80-af8d-489e-8ad2-c0fd05cce86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ghost_data = xr.open_dataset('/home/avilanov/data/providentia/obs/ghost/EEA_AQ_eReporting/1.5/hourly/sconcno2/sconcno2_201805.nc')\n",
    "ghost_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
